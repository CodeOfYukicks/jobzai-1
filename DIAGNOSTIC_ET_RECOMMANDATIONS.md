# üîç Diagnostic: Workday & Ashby + Recommandations de Scalabilit√©

## ‚úÖ R√©sum√© du Diagnostic

### **Bonne nouvelle: Tous les fetchers fonctionnent !**

J'ai test√© tous les fetchers ATS et voici les r√©sultats:

| ATS | Status | Jobs r√©cup√©r√©s | Notes |
|-----|--------|----------------|-------|
| **Workday** (Nvidia) | ‚úÖ | 2,000 jobs | Fonctionne parfaitement |
| **Ashby** (6 entreprises) | ‚úÖ | 566 jobs | Toutes les entreprises OK |
| - Notion | ‚úÖ | 131 jobs | |
| - Linear | ‚úÖ | 18 jobs | |
| - Zapier | ‚úÖ | 30 jobs | |
| - Replit | ‚úÖ | 35 jobs | |
| - Ramp | ‚úÖ | 128 jobs | |
| - Deel | ‚úÖ | 224 jobs | |

**Total r√©cup√©r√© lors du test: 2,566 jobs**

---

## üêõ Pourquoi tu ne vois que Greenhouse, Lever, SmartRecruiters ?

### Hypoth√®se la plus probable:

Le CRON Cloud Function **a probablement timeout** ou **√©chou√© silencieusement** lors de la derni√®re ex√©cution.

**Preuves:**
1. ‚úÖ Les fetchers Workday/Ashby fonctionnent (test confirm√©)
2. ‚ùå Tu ne vois pas leurs jobs dans la BDD
3. ‚ö†Ô∏è Le timeout est de 540s (9 minutes)
4. ‚ö†Ô∏è L'enrichissement LLM est activ√© (tr√®s lent)

**Ce qui s'est probablement pass√©:**

```
1. CRON d√©marre
2. Fetch Greenhouse ‚úÖ (rapide)
3. Fetch Lever ‚úÖ (rapide)
4. Fetch SmartRecruiters ‚úÖ (lent mais OK)
5. Fetch Workday... üïê (en cours)
6. ‚è∞ TIMEOUT apr√®s 540s
7. Workday et Ashby non trait√©s ‚ùå
```

### V√©rification:

Pour confirmer, v√©rifie les logs Cloud Functions:
```bash
firebase functions:log --only fetchJobsFromATS --limit 50
```

Tu devrais voir des erreurs de timeout ou d'ex√©cution incompl√®te.

---

## üö® Probl√®mes critiques pour scale (100k+ jobs)

### 1. **Timeout Cloud Function (540s = 9 min)**
- Avec 100k+ jobs, m√™me sans enrichissement, tu d√©passeras ce timeout
- **Solution:** Architecture par queue (voir ci-dessous)

### 2. **Enrichissement LLM bloquant**
```typescript
// Dans fetchJobs.ts ligne 148-156
if (!normalized.skills?.length && normalized.description) {
    const skills = await extractSkillsWithLLM(...); // ‚ùå BLOQUANT
}
```
- Avec 50k jobs sans skills = 50k appels LLM s√©quentiels
- **Impossible** dans un timeout de 540s
- **Solution:** Enrichissement asynchrone en arri√®re-plan

### 3. **SmartRecruiters fait une requ√™te par job**
```typescript
// Dans atsFetchers.ts ligne 110-111
for (const p of postings) {
    const detailUrl = `https://api.smartrecruiters.com/.../postings/${id}`;
    const d = await fetchJson<any>(detailUrl); // ‚ùå 1 requ√™te par job
}
```
- 1000 jobs SmartRecruiters = 1000 requ√™tes HTTP s√©quentielles
- **Solution:** Parall√©lisation + rate limiting

### 4. **BulkWriter accumule tout en m√©moire**
```typescript
const batch = db.bulkWriter(); // Accumule TOUS les jobs
for (const j of jobs) {
    batch.set(ref, normalized); // Ajout en m√©moire
}
await batch.close(); // Flush √† la fin
```
- 100k jobs √ó ~5KB/job = **500MB** en m√©moire
- **Limite:** 1GiB configur√©e
- **Solution:** Batching par chunks

### 5. **Limitation arbitraire Workday**
```typescript
if (offset > 2000) break; // ‚ùå Max 2000 jobs par entreprise
```
- Certaines grandes entreprises ont 10k+ jobs sur Workday
- **Solution:** Configuration flexible par entreprise

---

## ‚úÖ Recommandations Architecture

### **Option 1: Architecture par Queue (RECOMMAND√â pour 100k+)**

#### Avantages:
- ‚úÖ **Pas de timeout global** - chaque source a son propre timeout
- ‚úÖ **Retry automatique** - si une source √©choue, elle est retent√©e
- ‚úÖ **Parall√©lisation contr√¥l√©e** - traite 10 sources en parall√®le max
- ‚úÖ **Monitoring pr√©cis** - tu sais exactement quelle source a √©chou√©
- ‚úÖ **Scalable √† l'infini** - peut g√©rer des millions de jobs

#### Architecture:

```mermaid
graph TD
    A[CRON Scheduler<br/>every 24h] -->|Cr√©e des t√¢ches| B[Cloud Task Queue]
    B -->|1 t√¢che par source ATS| C1[Worker: Greenhouse/Stripe]
    B -->|1 t√¢che par source ATS| C2[Worker: Workday/Nvidia]
    B -->|1 t√¢che par source ATS| C3[Worker: Ashby/Notion]
    B -->|...| C4[Worker: N sources]
    
    C1 & C2 & C3 & C4 -->|√âcrit jobs| D[(Firestore)]
    C1 & C2 & C3 & C4 -->|Cr√©e t√¢ches enrichissement| E[Enrichment Queue]
    
    E -->|Parallel workers| F1[Enrich Worker 1]
    E -->|Parallel workers| F2[Enrich Worker 2]
    E -->|Parallel workers| F3[Enrich Worker N]
    
    F1 & F2 & F3 -->|Mise √† jour skills| D
    
    style A fill:#e1f5ff
    style B fill:#fff3cd
    style D fill:#d4edda
    style E fill:#f8d7da
```

#### Code:

```typescript
// 1. CRON l√©ger qui cr√©e des t√¢ches (< 60s execution)
export const scheduleFetchJobs = onSchedule({
    schedule: 'every 24 hours',
    timeoutSeconds: 60,
}, async () => {
    const queue = getFunctions().taskQueue('fetchJobsQueue');
    
    console.log(`[SCHEDULER] Creating ${ATS_SOURCES.length} tasks`);
    
    for (const source of ATS_SOURCES) {
        await queue.enqueue({
            source,
            timestamp: Date.now(),
        });
    }
    
    console.log(`[SCHEDULER] All tasks created`);
});

// 2. Worker qui traite UNE source ATS
export const fetchJobsWorker = onTaskDispatched({
    retryConfig: {
        maxAttempts: 3,
        minBackoffSeconds: 60,
    },
    rateLimits: {
        maxConcurrentDispatches: 10, // Max 10 sources en parall√®le
    },
    memory: '2GiB',
    timeoutSeconds: 540, // 9 min par source
}, async (req) => {
    const { source, timestamp } = req.data;
    const db = admin.firestore();
    
    console.log(`[WORKER] Processing ${source.provider}/${source.company}`);
    
    try {
        // Fetch les jobs de CETTE source uniquement
        let jobs: NormalizedATSJob[] = [];
        
        if (source.provider === "greenhouse" && source.company) {
            jobs = await fetchGreenhouse(source.company);
        } else if (source.provider === "workday" && source.company) {
            jobs = await fetchWorkday(source.company, source.workdayDomain, source.workdaySiteId);
        }
        // ... autres providers
        
        // √âcriture par batches de 500
        const BATCH_SIZE = 500;
        let written = 0;
        
        for (let i = 0; i < jobs.length; i += BATCH_SIZE) {
            const chunk = jobs.slice(i, i + BATCH_SIZE);
            const batch = db.batch();
            
            for (const j of chunk) {
                const docId = `${j.ats}_${j.externalId}`;
                const ref = db.collection('jobs').doc(docId);
                const normalized = normalizeJob(j);
                
                batch.set(ref, {
                    ...normalized,
                    enrichmentStatus: 'pending', // √Ä enrichir plus tard
                }, { merge: true });
            }
            
            await batch.commit();
            written += chunk.length;
            console.log(`[WORKER] Written ${written}/${jobs.length} jobs`);
        }
        
        // Cr√©er des t√¢ches d'enrichissement
        const enrichQueue = getFunctions().taskQueue('enrichSkillsQueue');
        for (const j of jobs) {
            if (!j.skills?.length && j.description) {
                await enrichQueue.enqueue({
                    jobId: `${j.ats}_${j.externalId}`,
                });
            }
        }
        
        console.log(`[WORKER] ‚úÖ ${source.provider}/${source.company}: ${jobs.length} jobs`);
        
    } catch (error: any) {
        console.error(`[WORKER] ‚ùå ${source.provider}/${source.company}: ${error.message}`);
        throw error; // Retry automatique
    }
});

// 3. Worker d'enrichissement des skills
export const enrichSkillsWorker = onTaskDispatched({
    retryConfig: {
        maxAttempts: 2,
        minBackoffSeconds: 30,
    },
    rateLimits: {
        maxConcurrentDispatches: 50, // 50 enrichissements en parall√®le
        maxDispatchesPerSecond: 10,  // Rate limit OpenAI
    },
    memory: '512MiB',
    timeoutSeconds: 60,
}, async (req) => {
    const { jobId } = req.data;
    const db = admin.firestore();
    
    try {
        const jobRef = db.collection('jobs').doc(jobId);
        const jobDoc = await jobRef.get();
        
        if (!jobDoc.exists) return;
        
        const data = jobDoc.data()!;
        
        // Skip si d√©j√† enrichi
        if (data.enrichmentStatus === 'completed') return;
        
        // Enrichir avec LLM
        const skills = await extractSkillsWithLLM(
            `${data.title}\n${data.description}`
        );
        
        // Mettre √† jour
        await jobRef.update({
            skills,
            enrichmentStatus: 'completed',
            enrichedAt: admin.firestore.FieldValue.serverTimestamp(),
        });
        
        console.log(`[ENRICH] ‚úÖ ${jobId}: ${skills.length} skills`);
        
    } catch (error: any) {
        console.error(`[ENRICH] ‚ùå ${jobId}: ${error.message}`);
        // Marquer comme failed mais ne pas throw (pas de retry infini)
        await db.collection('jobs').doc(jobId).update({
            enrichmentStatus: 'failed',
        });
    }
});
```

#### D√©ploiement:

```bash
# 1. D√©ployer les fonctions
firebase deploy --only functions:scheduleFetchJobs,functions:fetchJobsWorker,functions:enrichSkillsWorker

# 2. Le CRON va automatiquement cr√©er les t√¢ches toutes les 24h
# 3. Monitoring dans la console Firebase
```

---

### **Option 2: Optimisations du syst√®me actuel (pour 10k jobs max)**

Si tu veux garder l'architecture actuelle mais l'optimiser:

#### A. D√©sactiver l'enrichissement LLM pendant le fetch

```typescript
// Dans fetchJobs.ts, COMMENTER lignes 148-156
// L'enrichissement sera fait en arri√®re-plan plus tard
```

#### B. Parall√©liser SmartRecruiters

```typescript
// Dans atsFetchers.ts, remplacer la boucle for par:
const detailPromises = postings.map(async (p) => {
    const id = p.id || p.uuid;
    try {
        const detailUrl = `...`;
        const d = await fetchJson<any>(detailUrl);
        // ... traitement
        return normalizedJob;
    } catch (e) {
        console.warn(`...`);
        return fallbackJob;
    }
});

const list = await Promise.all(detailPromises);
```

#### C. Augmenter les limites Cloud Function

```typescript
export const fetchJobsFromATS = onSchedule({
    // ...
    timeoutSeconds: 3600,  // 1 heure au lieu de 9 min
    memory: '4GiB',        // 4GB au lieu de 1GB
});
```

#### D. Batching intelligent

```typescript
// Remplacer bulkWriter par batching manuel
const BATCH_SIZE = 500;
for (let i = 0; i < jobs.length; i += BATCH_SIZE) {
    const chunk = jobs.slice(i, i + BATCH_SIZE);
    const batch = db.batch();
    
    for (const j of chunk) {
        // ... set
    }
    
    await batch.commit();
}
```

---

## üéØ Ma Recommandation

**Pour 100k+ jobs: Option 1 (Architecture par Queue)**

### Pourquoi?
- ‚úÖ **Fiabilit√©**: Pas de timeout global, retry automatique
- ‚úÖ **Scalabilit√©**: Supporte des millions de jobs
- ‚úÖ **Observabilit√©**: Tu vois exactement ce qui √©choue
- ‚úÖ **Performance**: Enrichissement en parall√®le
- ‚úÖ **Co√ªts**: Paye seulement pour ce qui est utilis√©

### Plan d'impl√©mentation:

1. **Phase 1** (2h): Impl√©menter l'architecture par queue
2. **Phase 2** (1h): Tester avec les sources actuelles
3. **Phase 3** (30min): D√©ployer en production
4. **Phase 4** (ongoing): Ajouter des sources progressivement

---

## üìä Comparaison des Options

| Crit√®re | Architecture actuelle | Avec optimisations | Architecture Queue |
|---------|----------------------|-------------------|-------------------|
| **Max jobs support√©s** | ~5k | ~20k | Illimit√© |
| **Timeout risk** | ‚ùå √âlev√© | ‚ö†Ô∏è Moyen | ‚úÖ Aucun |
| **Enrichissement LLM** | ‚ùå Bloquant | ‚ùå Bloquant | ‚úÖ Async |
| **Retry automatique** | ‚ùå Non | ‚ùå Non | ‚úÖ Oui |
| **Complexit√© code** | ‚≠ê Simple | ‚≠ê‚≠ê Moyen | ‚≠ê‚≠ê‚≠ê Avanc√© |
| **Temps impl√©mentation** | - | 1h | 3h |
| **Monitoring** | ‚ö†Ô∏è Basique | ‚ö†Ô∏è Basique | ‚úÖ D√©taill√© |
| **Co√ªt** | üí∞ | üí∞üí∞ | üí∞ |

---

## üîß Action imm√©diate pour voir Workday/Ashby

En attendant de choisir l'architecture, pour voir imm√©diatement les jobs Workday/Ashby:

```bash
# 1. D√©sactiver temporairement l'enrichissement LLM
# Commenter lignes 148-156 dans functions/src/fetchJobs.ts

# 2. Red√©ployer la fonction
firebase deploy --only functions:fetchJobsFromATS

# 3. Attendre 24h pour le prochain CRON
# OU trigger manuellement via la console Firebase
```

Ou si tu veux les voir imm√©diatement dans l'√©mulateur:

```bash
# 1. D√©marrer les √©mulateurs
firebase emulators:start

# 2. Dans un autre terminal:
cd functions
USE_EMULATOR=true npm run fetch:local

# 3. Les jobs appara√Ætront sur http://localhost:5178/jobs
```

---

**Question:** Tu veux que j'impl√©mente l'architecture par queue maintenant, ou tu pr√©f√®res d'abord faire les optimisations simples ?
